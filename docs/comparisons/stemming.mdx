---
id: stemming
title: Simple Search vs. Stemming
sidebar_label: Stemming
custom_edit_url: null
---
### 1. Introduction
What is stemming?
What did we compare?
How did we compare it?

What are our hypothesis, expectations?

### 2. Results
What are the results?



### Discussion
What are the biggest differences in precision and recall between our approaches and how can we explain them?

Looking at the f1 score fom our approaches we can see that both stemming approaches perform better than the standard baseline on most datasets.
Algorithmic stemming performs better than the standard analyzer on all datasets, it has the biggest gain on the LISA and NPL datasets.
Hunspell stemming performs worse than algorithmic stemming on most datasets except NPL where it performs slighlty better.
Hunspell stemming performs worse than the standard analyzer on the medline dataset.

The are a list of interesting questions that we can ask by just looking at these results:

1.   Why is algorithmic stemming performing better than the standard analyzer?
2.   Why is algorithmic stemming performing better that hunspell stemming?
3.   Why is hunspell stemming performing worse that the standard analyzer on the Medline dataset?
4.   Why is hunspell stemming performing better that the algorithmic stemmer on the NPL dataset?

To break down these results on the individual querys and finnally word matches and to analze under and over stemming that leads to these results, 
we need to first look at the precision and recall scores individually and then extract the false positives and negatives that lead to these results and analyse them.


#### 1. Algorithmic stemming improvements 

Stemmer 
(NPL both improvements)
Why is hunspell stemming performing better on the NPL dataset

#### 2. Algorithmic stemming vs dictionary stemming

#### 3. Dictionary stemming errors

#### 4. Conclusion
