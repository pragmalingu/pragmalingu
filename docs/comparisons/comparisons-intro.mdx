---
id: comparisons-intro
title: Let's compare...
sidebar_label: Introduction
custom_edit_url: null
---
import useBaseUrl from '@docusaurus/useBaseUrl';

<img
  alt="Rikki"
  src={useBaseUrl('img/Rikki_Comparison.png')}
  class= "mascott"
/>

Welcome to our Benchmark section.

Since there are many approaches for Natural Language Processing it's helpful to be aware of some already established basics before getting started.
To make things easier for you, we have collected some already established benchmarks and helpful concepts, ready to be used, in this section.

<br />

We collected some free available data sets to test these methods on. 
This table shows a short overview comparison of all researched data sets so far:

| Corpus                   | Download | Documents | Queries | Notation                        |
|--------------------------|----------|-----------|---------|---------------------------------|
| ADI                      | Free     | 83        | 35      | .I, .T, .W, .A                  |
| CACM                     | Free     | 3,204     | 64      |  .I, .T, .W, .B, .A, .N, .X     |
| CISI                     | Free     | 1,460     | 112     |  .I, .T, .W, .B, .A, .X         |
| Cranfield                | Free     | 1,400     | 225     | .I, .T, .W, .B, .A              |
| LISA                     | Free     | 6004      | 35      | *, #                            |
| Medline                  | Free     | 1,033     | 30      | .I, .W                          |
| NPL                      | Free     | 11,429    | 93      |  /                              |
| Time                     | Free     | 423       | 83      | \*TEXT,\*FIND                   |

Which data set is best for evaluation depends strongly on the use case.
To get a better understanding of what the data sets look like, check out our [Data Set Comparison](./guides/data-comparison.mdx).

Feel free to browse through our Comparisons:
* [Stemming](#./stemming.mdx)
* [Embeddings](#./embeddings.mdx) 
