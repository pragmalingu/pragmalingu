<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.4">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="PragmaLingu Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="PragmaLingu Blog Atom Feed"><title data-react-helmet="true">Basic Terms | PragmaLingu</title><meta data-react-helmet="true" property="og:url" content="https://www.pragmalingu.de/docs/guides/basic-definitions"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Basic Terms | PragmaLingu"><meta data-react-helmet="true" name="description" content="With this guide, we want to provide you with some quick definitions on the basic Natural Language Processing (NLP) terms used in our experiments. If there are terms that you think should be explained as well, please let us know."><meta data-react-helmet="true" property="og:description" content="With this guide, we want to provide you with some quick definitions on the basic Natural Language Processing (NLP) terms used in our experiments. If there are terms that you think should be explained as well, please let us know."><link data-react-helmet="true" rel="shortcut icon" href="/img/kleines_Icon_1.png"><link data-react-helmet="true" rel="canonical" href="https://www.pragmalingu.de/docs/guides/basic-definitions"><link data-react-helmet="true" rel="alternate" href="https://www.pragmalingu.de/docs/guides/basic-definitions" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://www.pragmalingu.de/docs/guides/basic-definitions" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.81dc1e69.css">
<link rel="preload" href="/assets/js/runtime~main.0c7868c6.js" as="script">
<link rel="preload" href="/assets/js/main.0ea2e181.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/kleines_Icon_2.webp" alt="PragmaLingu" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/kleines_Icon_2.webp" alt="PragmaLingu" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title"></b></a><a class="navbar__item navbar__link" href="/docs/comparisons/comparisons-intro">Comparisons</a><a class="navbar__item navbar__link" href="/docs/experiments/experiments-intro">Experiments</a><a class="navbar__item navbar__link" href="/docs/guides/guides-intro">Guides</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/about/team">About</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/pragmalingu" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">üåú</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">üåû</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><button class="clean-btn backToTopButton_35hR" type="button" title="Scroll to top"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/guides/guides-intro">Introduction</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" href="/docs/guides/basic-definitions">Basic Definitions</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/guides/pragmatics">Pragmatics</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/guides/data-comparison">Data Sets</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/guides/how-to-parse">Data Parsing for Elasticsearch</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/guides/elastic-setup">Set up Elasticsearch</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/guides/notebooks">Working with Notebooks</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/guides/ranking-api">Ranking Evaluation API</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">On this page</button></div><div class="markdown"><header><h1 class="h1Heading_27L5">Basic Terms</h1></header><p>With this guide, we want to provide you with some quick definitions on the basic Natural Language Processing (NLP) terms used in our experiments. If there are terms that you think should be explained as well, please <a href="/docs/about/team">let us know</a>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="nlp---natural-language-processing"></a>NLP - Natural Language Processing<a class="hash-link" href="#nlp---natural-language-processing" title="Direct link to heading">#</a></h2><p>First, let&#x27;s clarify what NLP is. NLP stands for ‚ÄúNatural Language Processing‚Äù and is a sub-field of Computer Science which works with natural language. Natural language (for example English, German, Japanese) is a language that was naturally created by people to communicate and has evolved throughout use and repetition. As opposed to  artificial languages or computer code, there is not a large degree of planning or optimization involved when the rules of a natural language somehow change.
Since Natural Language sometimes appears arbitrary (in comparison with artificial languages) and does not always follow strict rules, it is very difficult to process it automatically. Therefore, NLP began to get more important in the 1950s as an intersection of artificial intelligence and linguistics. Nowadays, it is a separate field of research.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="corpus-pl-corpora"></a>Corpus (pl. Corpora)<a class="hash-link" href="#corpus-pl-corpora" title="Direct link to heading">#</a></h2><p>A text corpus (plural corpora) is a collection of texts which have been collected to be used in Natural Language Processing. Often there are not only texts in a corpus but also some useful information; for example on the author or the publishing date. A corpus can contain texts from one language (monolingual corpus), or texts from several languages (multilingual corpus). Corpora are usually created according to the application, which is why not every corpus is suitable for every task; e.g. <a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener noreferrer">&#x27;The Stanford Question Answering Dataset&#x27;</a>, which was collected specially to train question and answering tasks.
Every corpus is structured differently, which is why analyzing a corpus alone can take a lot of time.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="tokens-vs-types"></a>Tokens vs. Types<a class="hash-link" href="#tokens-vs-types" title="Direct link to heading">#</a></h2><p>The definition of ‚Äúword‚Äù is not very clear in linguistics. For our purposes we require a better and more specific definition.
When we automatically process language and talk about &quot;words&quot;, we usually distinguish between <strong>Types</strong> and <strong>Tokens</strong>.
The <strong>Tokens</strong> are all the &quot;words&quot; in a running text that are separated through punctuation and spaces.
On the other hand, the <strong>Types</strong> are the distinct classes of Tokens in a sentence or in a text.
As an example:</p><p>Sentence 1: <code>A rose is a rose</code></p><p>This sentence has 3 Types (<code>a</code>,<code>rose</code>,<code>is</code>) and 5 Tokens (<code>a</code>,<code>rose</code>,<code>is</code>,<code>a</code>,<code>rose</code>). Since <code>a</code> and <code>rose</code> are repeated twice, they only count as 1 Type each.
If we replace the last token <code>rose</code> -  the number of Types changes:</p><p>Sentence 2: <code>A rose is a roses</code>
(Please note: This sentence is ungrammatical on purpose, because we wanted to show how small differences can influence the Type ratio)</p><p>Now we have 4 distinct <strong>Types</strong> (<code>a</code>,<code>rose</code>,<code>is</code>,<code>roses</code>) and still 5 <strong>Tokens</strong> (<code>a</code>,<code>rose</code>,<code>is</code>,<code>a</code>,<code>roses</code>).
Note that even if the word is the same, but has a different ending (for example <code>roses</code> is the plural of <code>rose</code>), it counts as a separate <strong>Type</strong>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="tokenization"></a>Tokenization<a class="hash-link" href="#tokenization" title="Direct link to heading">#</a></h2><p>Tokenization is the process of splitting a long sequence of symbols (like a sentence or a text) into <strong>Tokens</strong>. <strong>Tokens</strong> are defined in the <code># Tokens vs.Types</code> paragraph above. In many languages, words are separated by spaces and punctuation marks. Therefore, many tokenizers split sentences into words at these markers. <br>
For example, the sentence <code>A rose is a rose.</code> can be split into <code>A</code>, <code>rose</code>, <code>is</code>, <code>a</code>, <code>rose</code>, <code>.</code>.
Depending on the tokenizer the dot (<code>.</code>) could be stripped away as well.</p><p>But some cases make it difficult (or incorrect) to tokenize in this manner. Some symbol sequences do not make sense when they get split up by simply following these rules.<br>
For example, proper names like <code>U.K.</code>, <code>San Francisco</code>, or splitting at apostrophe - like in the case of <code>s&#x27;more</code>. <br>
That&#x27;s why a tokenizer often needs information about the language to split the sentence in a way that makes sense. For other languages such as Japanese or Chinese, you can&#x27;t split at  spaces at all.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="lemmatization"></a>Lemmatization<a class="hash-link" href="#lemmatization" title="Direct link to heading">#</a></h2><p>With lemmatization, we try to connect the words in the text to their basic form, their <strong>Lemma</strong>. The <strong>Lemma</strong> is the root - or the dictionary form - of a word. Lemmatization is done by removing all prefixes and suffixes, according to the morphological rules of the language.
In this way, we reduce the number of <strong>Tokens</strong> of a text and get more <strong>Types</strong>. A lemmatizer would map all the words to their common lemma.<br>
For example, the lemmatizer will recognize that <code>mice</code> is a form of <code>mouse</code> and <code>froze</code> &amp; <code>frozen</code> are forms of <code>freeze</code>.
There are some languages, such as Arabic, which cannot be processed properly without lemmatization.</p><p>But since a lemmatizer needs a lot of information about the morphology of a language, this usually slows down the search process significantly and leads to an enormous amount of data.
However, if lemmatization is well adapted to the data, it can significantly improve the search results.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="stemming"></a>Stemming<a class="hash-link" href="#stemming" title="Direct link to heading">#</a></h2><p>Stemming is a simpler version of lemmatization, which does not rely on full morphological analysis. Depending on the method used it mainly strips off prefixes or suffixes (from lists of such) from the beginning or the end of a word to reduce it to its <strong>Stem</strong>.
In English, the <strong>Stem</strong> is generally the part of the word that doesn&#x27;t change when you apply grammatical rules. Stemming is one of the most commonly used methods when dealing with search engines since it is easier than lemmatization.</p><p>The goal of a stemmer is to remove all morphological features from a word and create truncated, ambiguous <strong>Stems</strong>.<br>
For example, <code>learning</code> changes to <code>learn</code> after stemming. <br>
In most cases, the search query is only improved by a stemmer if the query is not too long. Otherwise, there is a risk that too many irrelevant results will be returned.
But, if there are short queries, stemming can be very helpful as small grammatical deviations can be included in the search. However, one must be careful with too much stemming. Sometimes, stemming may produce a part of the word which is not linguistically valid. If the stemmer cuts off too much information, the word could become too short and lose semantic meaning. This is called overstemming. This occurs, for example, when the stemmer reduces <code>saw</code> to <code>s</code>.
Always keep in mind that the quality of a stemmer varies greatly from language to language because some languages have more morphological derivations than others.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="stop-words"></a>Stop Words<a class="hash-link" href="#stop-words" title="Direct link to heading">#</a></h2><p>In most languages, the most frequent words are also those that do not carry much (or any) meaning. In English such words include <code>is</code>, <code>a</code>, <code>and</code>, or <code>the</code>. To only get relevant search queries, we try to remove those words. These words are called <strong>stop words</strong> since they don&#x27;t retrieve any useful information while still being processed. Ignoring stop words is a way to make the search more efficient and to get more relevant data.
To ignore or remove them we can simply consider most of the 10-100 most frequent words as <strong>stop words</strong> or use some of the already existing <strong>stop word</strong> lists depending on the language we want to search.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="cosine-similarity"></a>Cosine Similarity<a class="hash-link" href="#cosine-similarity" title="Direct link to heading">#</a></h2><p>In NLP, language can be represented as a vector of features; so called <strong>embeddings</strong>. These can represent words, sentences, or even whole documents. To use these <strong>embeddings</strong> in, for example, Information Retrieval, it is necessary to have a way of computing the similarity between them. The most common way is to measure the difference between those vectors. This can be achieved by computing the cosine similarity. Hereby the angle between two vectors is calculated. This is irrespective of their size, which makes it perfect for NLP tasks since, in language, <strong>embeddings</strong> rarely have the same size.
The smaller the angle between the vectors, the more similar they are. Which means if the angle is 0, the vectors are identical, therefore the cosine similarity is 1.</p><br><br><p><strong>Acknowledgements:</strong><br>
Thanks to Kenny Hall and Irina Temnikova for proofreading this article.</p><div class="col text--right"><em><small>Written by <strong>Miriam Rupprecht</strong>,  August 2020</small></em></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/guides/guides-intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">¬´ Introduction</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/guides/pragmatics"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Pragmatics ¬ª</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#nlp---natural-language-processing" class="table-of-contents__link">NLP - Natural Language Processing</a></li><li><a href="#corpus-pl-corpora" class="table-of-contents__link">Corpus (pl. Corpora)</a></li><li><a href="#tokens-vs-types" class="table-of-contents__link">Tokens vs. Types</a></li><li><a href="#tokenization" class="table-of-contents__link">Tokenization</a></li><li><a href="#lemmatization" class="table-of-contents__link">Lemmatization</a></li><li><a href="#stemming" class="table-of-contents__link">Stemming</a></li><li><a href="#stop-words" class="table-of-contents__link">Stop Words</a></li><li><a href="#cosine-similarity" class="table-of-contents__link">Cosine Similarity</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Content</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/comparisons/comparisons-intro">Comparisons</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/experiments/experiments-intro">Experiments</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/guides/guides-intro">Guides</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/pragmalingu" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://discord.gg/uzXWeKQ" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="http://eepurl.com/heTv2X" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Newsletter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/pragmalingu" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a class="footer__link-item" href="/docs/about/team">About</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/impressum">Impressum</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2021 PragmaLingu</div></div></div></footer></div>
<script src="/assets/js/runtime~main.0c7868c6.js"></script>
<script src="/assets/js/main.0ea2e181.js"></script>
</body>
</html>