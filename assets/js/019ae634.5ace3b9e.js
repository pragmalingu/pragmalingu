(self.webpackChunkpragmalingu_github_io=self.webpackChunkpragmalingu_github_io||[]).push([[87],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return c},kt:function(){return h}});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=d(n),h=i,m=u["".concat(l,".").concat(h)]||u[h]||p[h]||r;return n?a.createElement(m,o(o({ref:t},c),{},{components:n})):a.createElement(m,o({ref:t},c))}));function h(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var d=2;d<r;d++)o[d]=n[d];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},3362:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return o},metadata:function(){return s},toc:function(){return l},default:function(){return c}});var a=n(2122),i=n(9756),r=(n(7294),n(3905)),o={id:"how-to-parse",title:"How to Parse Data",sidebar_label:"Data Parsing for Elasticsearch",custom_edit_url:null},s={unversionedId:"guides/how-to-parse",id:"guides/how-to-parse",isDocsHomePage:!1,title:"How to Parse Data",description:"1. Let's Start",source:"@site/docs/guides/how-to-parse.mdx",sourceDirName:"guides",slug:"/guides/how-to-parse",permalink:"/docs/guides/how-to-parse",editUrl:null,version:"current",sidebar_label:"Data Parsing for Elasticsearch",frontMatter:{id:"how-to-parse",title:"How to Parse Data",sidebar_label:"Data Parsing for Elasticsearch",custom_edit_url:null},sidebar:"guides",previous:{title:"Free-To-Use Data Sets",permalink:"/docs/guides/data-comparison"},next:{title:"How to set up an Elasticsearch Instance",permalink:"/docs/guides/elastic-setup"}},l=[{value:"1. Let&#39;s Start",id:"1-lets-start",children:[]},{value:"2. Analyze Data",id:"2-analyze-data",children:[]},{value:"3. Parse Data",id:"3-parse-data",children:[]},{value:"4. Problems",id:"4-problems",children:[]},{value:"5. Conclusion",id:"5-conclusion",children:[]}],d={toc:l};function c(e){var t=e.components,n=(0,i.Z)(e,["components"]);return(0,r.kt)("wrapper",(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h3",{id:"1-lets-start"},"1. Let's Start"),(0,r.kt)("p",null,"To start experimenting and evaluating different Natural Language Processing (NLP) methods, it is necessary to transform the data that you want to use into a suitable form."),(0,r.kt)("p",null,"Therefore, you should start by answering the following three questions:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"What ",(0,r.kt)("strong",{parentName:"li"},"does")," the data look like?"),(0,r.kt)("li",{parentName:"ol"},"How do we ",(0,r.kt)("strong",{parentName:"li"},"want")," the data to look like?"),(0,r.kt)("li",{parentName:"ol"},"What kind of ",(0,r.kt)("strong",{parentName:"li"},"preprocessing")," would we want to apply first?")),(0,r.kt)("p",null,"Since we are mainly working with Elasticsearch by trying to improve the search results, the third question is not as relevant for us as the other ones. Most preprocessing such as tokenization, stemming, lemmatization, ignoring stop words, etc. will be applied to raw data. Since Elasticsearch includes automatic tokenization during indexing, we won't cover it here. Preprocessing will be excluded for the time being. If you think it would be interesting to include it in our guide, please don't hesitate ",(0,r.kt)("a",{parentName:"p",href:"/docs/about/team"},"to write to us"),"."),(0,r.kt)("p",null,"The code in the guide is programmed in Python3, since Python offers great tools for language processing."),(0,r.kt)("details",null,(0,r.kt)("summary",null,'What is "tokenization"?'),(0,r.kt)("p",null,"When we talk about ",(0,r.kt)("inlineCode",{parentName:"p"},"Tokens"),' we basically mean a sequence of characters or bits that belong together. Within a sentence by `Tokens\u2019 we mostly mean words. Tokenization is the process of splitting a long sequence like a sentence into separate Tokens.\nFor example the sentence "The man bought a big fish." could be split into this list of Tokens: ',"['The','man','bought','a','big','fish']","\nFind more about Tokenization on our ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/basic-definitions#tokenization"},"definition page"),".")),(0,r.kt)("details",null,(0,r.kt)("summary",null,'What is "stemming"?'),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Stem"),' is that part of the word that does not change when you apply grammatical rules. Stemming tries to remove all morphological features from a word so that there are fewer different Tokens. A word like "learning", would for example change to "learn". If the stemmer cuts off too much information, the word could become too short and lose semantic meaning. This is called overstemming.\nRead more about stemming on our ',(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/basic-definitions#stemming"},"definition page"),".")),(0,r.kt)("details",null,(0,r.kt)("summary",null,'What is "lemmatization"?'),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"Lemmatization")," means transforming words into their ",(0,r.kt)("inlineCode",{parentName:"p"},"lemmas"),". A ",(0,r.kt)("inlineCode",{parentName:"p"},"Lemma")," is similar to the ",(0,r.kt)("inlineCode",{parentName:"p"},"Stem")," since it is also an invariable form of the word which does not contain any prefixes/suffixes which appear when grammatical rules are applied to it. But, lemmatization doesn't just roughly cut off information. It tries to replace the word by its basic (or ",(0,r.kt)("inlineCode",{parentName:"p"},"dictionary"),') form. For example "lovingly" would connect to "love", and not to "loving".\nYou can find more about lemmatization on our ',(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/basic-definitions#lemmatization"},"definition page"),".")),(0,r.kt)("h3",{id:"2-analyze-data"},"2. Analyze Data"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"What does my Data look like?"),"\nBefore you can start parsing, you have to take a closer look at the data that you want to parse."),(0,r.kt)("p",null,"It is important to determine what kind of information you have. Is it just text that you are parsing? Is there any additional information such as the author\u2019s name, a title, date(s) or something similar? If there is additional information, is it labelled separately, or is it included in the text?"),(0,r.kt)("p",null,"The texts, which are the most difficult to parse, are those that do not provide any additional information about the parts of the data, or those that consist exclusively of running, non-stop text."),(0,r.kt)("p",null,"Since we decided to use data sets that are specifically provided for NLP tasks, we knew that they would have a certain structure. So we only had to deal with the different characteristics of the data sets and not with structuring them beforehand."),(0,r.kt)("p",null,"We downloaded all the data sets from the ",(0,r.kt)("a",{parentName:"p",href:"http://ir.dcs.gla.ac.uk/resources/test_collections/"},"University of Glasgow"),", looked at them in detail and wrote detailed descriptions on the information that each corpus provides.\nWe could determine that the corpora ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#cranfield"},"Cranfield"),", ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#cacm"},"CACM"),", ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#cisi"},"CISI")," and ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#adi"},"ADI"),' use very similar notations. The text of each document is always marked with a line that only contains ".W" at the beginning:'),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},".W\none-dimensional transient heat conduction into a double-layer\nslab subjected to a linear heat input for a small time\ninternal .\nanalytic solutions are presented for the transient heat\nconduction in composite slabs exposed at one surface to a\ntriangular heat rate .  this type of heating rate may occur, for\nexample, during aerodynamic heating .\n")),(0,r.kt)("p",null,"In this way, the additional information can be clearly identified by the other markers provided."),(0,r.kt)("p",null,"If you don't want to determine the markers on your own, we have already done all the work by analyzing every single ",(0,r.kt)("a",{parentName:"p",href:"/docs/guides/data-comparison"},"Data Set")," and even wrote an ",(0,r.kt)("a",{parentName:"p",href:"/docs/guides/data-comparison"},"overview table"),"."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"How do we want the data to look like?"),"\nAfter we analyzed our data properly, we can move on to the parsing part. Depending on how you want to use the data, you have to adapt your code for the right format output."),(0,r.kt)("p",null,"To be able to work with Elasticsearch we first have to index all the documents. You can read about what that exactly means and how to set up an Elasticsearch instance in our ",(0,r.kt)("a",{parentName:"p",href:"/docs/guides/elastic-setup"},"Elasticsearch Guide"),"."),(0,r.kt)("p",null,"The documents that we want to index, need the following format:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"doc = {\n    'author': 'kimchy',\n    'text': 'Elasticsearch: cool. bonsai cool.',\n    'title': 'Cool things',\n}\n")),(0,r.kt)("p",null,"Further information such as the author(s), title, publication date, etc. can be added as searchable fields using the format ",(0,r.kt)("inlineCode",{parentName:"p"},"'field_name': 'content'"),". To improve the search results, later on, it is definitely helpful to include as much additional information as possible."),(0,r.kt)("p",null,"To be able to index all the documents in one go, we parsed our documents into a dictionary of dictionaries, which can be easily iterated on later.\nThe details will be covered in the parsing section."),(0,r.kt)("p",null,"For evaluation, we use the ",(0,r.kt)("a",{parentName:"p",href:"https://elasticsearch-py.readthedocs.io/en/master/api.html?highlight=_rank_eval#elasticsearch.Elasticsearch.rank_eval"},"Elasticsearch Ranking evaluation API"),". For it, we need some search queries and a list of documents that are relevant for the queries, called ",(0,r.kt)("inlineCode",{parentName:"p"},"relevance assessments"),". A description of how to use the Elasticsearch Ranking evaluation API can be found in our ",(0,r.kt)("a",{parentName:"p",href:"/docs/guides/ranking-api"},"Ranking evaluation API Guide"),".\nThe search queries, relevance assessments and the index name of the indexed documents are fed to the Ranking evaluation API as the evaluation body."),(0,r.kt)("p",null,"The evaluation body requires the following format, in Python we simply used nested dictionaries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'eval_body = {\n    "requests": [\n        {\n            "id": "Query_1",\n            "request": {\n                "query": { "match": { "text": "\\nwhat are the structural and aeroelastic problems associated with flight\\nof high speed aircraft .\\n" }}\n            },\n            "ratings": [\n                { "_index": "pragmalingu-cranfield-corpus", "_id": "184", "rating": 1 },\n                { "_index": "pragmalingu-cranfield-corpus", "_id": "29", "rating": 1 },\n                [...]\n            ]\n        },\n        {\n            "id": "Query_2",\n            "request": {\n                "query": { "match": { "text":  "text": "\\nwhat problems of heat conduction in composite slabs have been solved so\\nfar .\\n"}}\n            },\n            "ratings": [\n                { "_index": "pragmalingu-cranfield-corpus", "_id": "12", "rating": 1 },\n                { "_index": "pragmalingu-cranfield-corpus", "_id": "15", "rating": 1 },\n                [...]\n            ]\n        },\n        [...]\n    ],\n    "metric": {\n      "precision": {\n        "k" : 20,\n        "relevant_rating_threshold": 1,\n        "ignore_unlabeled": "false"\n      }\n   }\n')),(0,r.kt)("h3",{id:"3-parse-data"},"3. Parse Data"),(0,r.kt)("p",null,"Now that we've figured out what the data looks like and how we want it structured in the end, we can finally start with parsing.\nSince it's easier to demonstrate parsing by using a practical example, we picked one of our ",(0,r.kt)("a",{parentName:"p",href:"/docs/guides/data-comparison"},"8 freely available Data Sets"),".\nWe chose the ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#cranfield"},"Cranfield Corpus"),". On the one hand, because it uses the same notation as CACM, CISI and ADI, and therefore the code can be easily adapted to parse the other corpora as well.\n(That's the reason why we also started parsing the Cranfield corpus for our experiments)\nOn the other hand, because it contains a lot of additional information and didn't cause major problems while parsing.\nFor these reasons, it seems that it is a perfect example to show you our approach step by step.\nIn the last section, we will also talk about some problems we had while parsing the other corpora.\nSo let's just dive into it!"),(0,r.kt)("h4",{id:"31-cranfield-corpus"},"3.1. Cranfield Corpus"),(0,r.kt)("p",null,"You can get the corpus from ",(0,r.kt)("a",{parentName:"p",href:"http://ir.dcs.gla.ac.uk/resources/test_collections/cran/"},"this link"),".\nFor detailed information about the format of the files, see the PragmaLingu ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/comparisons/overview"},"Comparisons"),".\nIn Colab, you have to add the following lines:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"!wget http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n!tar -xf cran.tar.gz\n")),(0,r.kt)("p",null,"After downloading it, you should make sure that you set the paths of every file that you want to parse:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"PATH_TO_CRAN_TXT = '/content/cran.all.1400'\nPATH_TO_CRAN_QRY = '/content/cran.qry'\nPATH_TO_CRAN_REL = '/content/cranqrel'\n")),(0,r.kt)("h4",{id:"32-parse-for-indexing"},"3.2. Parse for Indexing"),(0,r.kt)("p",null,"To create an index in Elasticsearch for the Cranfield corpus, we only need the documents file first. In our case, this is the file ",(0,r.kt)("inlineCode",{parentName:"p"},"cran.all.1400"),".\nConveniently, every new document begins with the ID marker '.I', directly followed by the ID. Therefore, we can start by splitting all entries at this marker. Detailed definitions of all the markers can be found ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#cranfield"},"here")),(0,r.kt)("p",null,"We get a list of all the document entries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"ID_marker = re.compile('\\.I.')\n \ndef get_data(PATH_TO_FILE, marker):\n  \"\"\"\n  Reads the file and splits the text into entries at the ID marker '.I'.\n  The first entry is empty, so it is removed.\n  'marker' contains the regex at which we want to split\n  \"\"\"\n  with open (PATH_TO_FILE,'r') as f:\n    text = f.read().replace('\\n',\" \")\n    lines = re.split(marker,text)\n    lines.pop(0)\n  return lines\n \ntxt_list = get_data(PATH_TO_CRAN_TXT, ID_marker)\nqry_list = get_data(PATH_TO_CRAN_QRY, ID_marker)\n")),(0,r.kt)("p",null,"As the search queries are also separated by the ID marker, we can split them up in the same step. But we only need the qry_list later."),(0,r.kt)("p",null,"Afterwards, we can split the information in every entry using the other information markers. To make the indexing in Elasticsearch easier, we are going to store all documents in one parsable dictionary of dictionaries as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from collections import defaultdict\nimport re\n \nchunk_start = re.compile('\\.[A,B,T,W]')\ntxt_data = defaultdict(dict)\n \nfor line in txt_list:\n  entries= re.split(chunk_start,line)\n  id = entries[0].strip()\n  title = entries[1]\n  author = entries[2]\n  publication_date = entries[3]\n  text = entries[4]\n  txt_data[id]['title'] = title\n  txt_data[id]['author'] = author\n  txt_data[id]['publication_date'] = publication_date\n  txt_data[id]['text'] = text\n")),(0,r.kt)("p",null,"This corpus is well-structured and has a clear notation, but we have to be careful, as in some corpora not all entries include the same information. For example, if some entries don't have an author or a publication date, we have to change the code likewise and try to prepare for these special cases. But we're going to look into that later."),(0,r.kt)("p",null,"After we parsed all our documents, we can now pass them one by one to the Elasticsearch index:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'cran_index = "cranfield-corpus"\n \nfor ID, doc_data in txt_data.items():\n  es.index(index=cran_index, id=ID, body=doc_data)\n')),(0,r.kt)("p",null,"Now that the index is set we can start parsing the evaluation body for the Ranking API."),(0,r.kt)("h4",{id:"33-parse-for-evaluation-body"},"3.3. Parse for Evaluation Body"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Queries"),"\nSince we already split the queries into a list while preparing the documents, we can continue with using the qry_list."),(0,r.kt)("p",null,"With the queries, it is similar to the documents. We start parsing their entries with the ID-tag and continue with splitting every entry into smaller pieces. The queries only consist of the ID and the query, so it's way easier to get that information:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from collections import defaultdict\nimport re\n \nchunk_start = re.compile('\\.[W]')\nqry_data = defaultdict(dict)\n \nfor n in range(0,len(qry_list)-1):\n  line = qry_list[n+1]\n  _ , question = re.split(chunk_start,line)\n  qry_data[n+1]['question'] = question\n")),(0,r.kt)("p",null,"Counting the queries with the range operator was an easy way to do this, but of course, it would also work to split the ID and transform it to an ",(0,r.kt)("inlineCode",{parentName:"p"},"int()")," ."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Relevance Assessments"),"\nIf we don't need the special rating that is provided by the Cranfield corpus (read about that ",(0,r.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/data-comparison#cranfield"},"here"),"). We can simply parse the file by splitting it into lines and only save the query-ID and the document-ID:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"cran_rel = defaultdict(list)\n \nwith open (PATH_TO_CRAN_REL,'r') as f:\n  for line in f:\n    line = re.split(' ',line)\n    cran_rel[int(line[0])].append(line[1])\n")),(0,r.kt)("p",null,"Otherwise, it would also be possible to parse the file as a NumPy array for easier accessibility to the additional ratings:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"cran_rel_data = open(PATH_TO_CRAN_REL)\ncran_np = np.loadtxt(cran_rel_data, dtype=int)\n \ncran_rel_rat = defaultdict(list)\nfor row in cran_np:\n  cran_rel_rat[row[0]].append(tuple(row[1:]))\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},"Evaluation Body"))),(0,r.kt)("p",null,"Now that we have all the data ready, we can feed it to a function that creates an evaluation body for the Ranking evaluation API:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'cran_index = "cranfield-corpus"\n \ndef create_query_body(query_dict, rel_dict, index_name):\n  """\n  The function creates a request for every query in query_dict and rates the relevant documents with rel_dict to 1.\n  The index name has to be identical to the index where the documents are stored.\n  An evaluation body for the Elasticsearch ranking API is returned.\n  """\n  eval_body = {\n      "requests":\'\',\n      "metric": {\n          "precision": {\n              "k" : 20,\n              "relevant_rating_threshold": 1,\n              "ignore_unlabeled": "false"\n              }\n      }\n  }\n  requests = []\n  current_request = defaultdict(lambda: defaultdict())\n  current_rel = {"_index": index_name, "_id": \'\', "rating": int}\n  for query_ID, query_txt in query_dict.items():\n    current_query = {"query": { "match": { "text": \'\' }}}\n    current_query["query"]["match"]["text"] = query_txt[\'question\']\n    current_request["id"] = \'Query_\'+str(query_ID)\n    current_request["request"] = current_query.copy()\n    current_request["ratings"] = [{"_index": index_name, "_id": str(el), "rating": 1} for el in rel_dict[query_ID]]\n    requests.append(current_request.copy())\n  eval_body["requests"] = requests\n  return eval_body\n \n# create the eval_body\ncran_create = create_query_body(cran_qry_data, cran_rel, cran_index)\n# dump the body to json and feed it to Ranking API\ncran_eval_body = json.dumps(cran_create)\ncran_res = es.rank_eval(cran_eval_body, cran_index)\n# print the results\nprint(json.dumps(cran_res, indent=4, sort_keys=True))\n')),(0,r.kt)("p",null,"And that was all about it. As already mentioned, it is not always that easy with every corpus. Therefore, in the next section, we will introduce you to a few problems that we have encountered, and that can save you a lot of time if you know them in advance."),(0,r.kt)("h3",{id:"4-problems"},"4. Problems"),(0,r.kt)("p",null,"Hereafter, we will briefly present some of the most noticeable problems of the 8 parsed corpora. These can become problems while parsing other corpora. It will show you how important it is to analyze the data beforehand."),(0,r.kt)("h4",{id:"41-split-files"},"4.1. Split Files"),(0,r.kt)("p",null,"Sometimes not all the data is collected in one file. For us, the only corpus in which this was the case, was LISA and it was solved quickly. But split documents can lead to additional work and therefore should be checked beforehand. Otherwise, it can happen that not all data is processed while parsing.\nThe LISA corpus is split into 14 different files which contain the 6004 document entries."),(0,r.kt)("p",null,"We solved it with parsing the file names with a regex:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"file_regex = re.compile('LISA[0-5]')\nlisa_files = [i for i in os.listdir(PATH_TO_LISA_TXT) if os.path.isfile(os.path.join(PATH_TO_LISA_TXT,i)) and \\\n         re.match(file_regex,i)]\n \nfor name in lisa_files:\n  lisa_txt_list.extend(get_data(PATH_TO_LISA_TXT+name, txt_entry_marker))\n")),(0,r.kt)("h4",{id:"42-information-inconsistencies"},"4.2. Information Inconsistencies"),(0,r.kt)("p",null,"While parsing the ADI, CACM and CISI corpora, we encountered another common problem. Although they have notations very similar to Cranfield, unfortunately, some inconsistencies caused problems during parsing. Since the data is annotated manually it can happen that for some entries the annotator just skipped the information tag if there wasn't any information to write. This caused code errors especially while parsing the document files.\nAfter initially assuming that we have a certain (and the same) amount of information for each entry, we quickly discovered that sometimes there was, for example, no author tag and other times there were more than one.\nWe will now take a quick look at some example problems and how we solved them:"),(0,r.kt)("p",null,"With 83 entries, ADI is the smallest of the corpora and therefore very manageable.\nIn ADI, each entry should have information regarding its ID (.I), title (.T), text (.W) and author (.A). Unfortunately, the information about the author and the tag (.A) is missing in some entries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},".I 7\n.T\na computer oriented photo-composition system for star\n.W\nthe system for producing nasa's scientific\nand technical aerospace reports, an example of computer\noriented automatic photo copy setting, produces copy\n at three times the speed of manual operation .  the discussion\nis limited to a punched paper tape application and\n does not cover aspects of a more sophisticated computer\n system.\n")),(0,r.kt)("p",null,"Our code quickly threw an error, so to get around this problem, after saving the ID, we added an if clause:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"adi_title_start = re.compile('\\.T')\nadi_author_start = re.compile('\\.A')\nadi_text_start = re.compile('\\.W')\n \n# process the document data\n \nadi_txt_data = defaultdict(dict)\n \nfor line in adi_txt_list:\n  entries = re.split(adi_title_start,line,1)\n  id = entries[0].strip()\n  no_id = entries[1]\n  if len(re.split(adi_author_start, no_id,1)) > 1:\n    no_id_entries = re.split(adi_author_start, no_id,1)\n    adi_txt_data[id]['title'] = no_id_entries[0]\n    no_title = no_id_entries[1]\n    no_title_entries = re.split(adi_text_start, no_title)\n    adi_txt_data[id]['author'] = no_title_entries[0]\n    adi_txt_data[id]['text'] = no_title_entries[1]\n  else:\n    no_id_entries = re.split(adi_text_start, no_id)\n    adi_txt_data[id]['title'] = no_id_entries[0]\n    adi_txt_data[id]['text'] = no_id_entries[1]\n")),(0,r.kt)("p",null,"A similar problem can be found in the CACM corpus. Each entry should contain information about the ID (.I), title (.T), text (.W), publication date (.B), author (.A), adding date (.N) and cross-references (.X). However, not every entry was assigned a text and an author."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},".I 4\n.T\nGlossary of Computer Engineering and Programming Terminology\n.B\nCACM November, 1958\n.N\nCA581103 JB March 22, 1978  8:32 PM\n.X\n4          5          4\n4          5          4\n4          5          4\n")),(0,r.kt)("p",null,"Since the entries without text and the entries without author are not always the same, we had to include two nested if clauses for parsing this corpus:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# process the text file\n \ncacm_chunk_title = re.compile('\\.[T]\\n')\ncacm_chunk_txt = re.compile('\\n\\.W\\n') # not enough\ncacm_chunk_txt_pub = re.compile('\\.[W,B]')\ncacm_chunk_publication = re.compile('\\.[B]\\n')\ncacm_chunk_author = re.compile('^\\.[A]\\n', re.MULTILINE)\ncacm_chunk_author_add_cross = re.compile('^\\.[A,N,X]\\n',re.MULTILINE) # not enough\ncacm_chunk_add_cross = re.compile('\\.[B,N,X]\\n')\n \n# process the document data\n \ncacm_txt_data = defaultdict(dict)\n \nfor line in cacm_txt_list:\n  entries= re.split(cacm_chunk_title,line)\n  id = entries[0].strip() #save id\n  no_id = entries[1]\n \n  if len(re.split(cacm_chunk_txt, no_id)) == 2: # is there text?\n    no_id_entries = re.split(cacm_chunk_txt_pub, no_id,1)\n    cacm_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n    cacm_txt_data[id]['text'] = no_id_entries[1].strip() # save text\n    no_title_txt = no_id_entries[1]\n \n    if len(re.split(cacm_chunk_author, no_title_txt)) == 2: # is there an author?\n      no_title_entries = re.split(cacm_chunk_author_add_cross, no_title_txt)\n      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n      cacm_txt_data[id]['author'] = no_title_entries[1].strip() # save author\n      cacm_txt_data[id]['add_date'] = no_title_entries[2].strip() # save add date\n      cacm_txt_data[id]['cross-references'] = no_title_entries[3].strip() # save cross-references\n \n    else:\n      no_title_entries = re.split(cacm_chunk_publication, no_title_txt)\n      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n      cacm_txt_data[id]['add_date'] = no_title_entries[1].strip() # save add date\n      cacm_txt_data[id]['cross-references'] = no_title_entries[1].strip() # save cross-references\n \n  else:\n    no_id_entries = re.split(cacm_chunk_publication, no_id,1)\n    cacm_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n    no_title = no_id_entries[1]\n \n    if len(re.split(cacm_chunk_author, no_title,1)) == 2: # is there an author?\n      no_title_entries = re.split(cacm_chunk_author_add_cross, no_title)\n      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n      cacm_txt_data[id]['author'] = no_title_entries[1].strip() # save author\n      cacm_txt_data[id]['add_date'] = no_title_entries[2].strip() # save add date\n      cacm_txt_data[id]['cross-references'] = no_title_entries[3].strip() # save cross-references\n \n    else:\n      no_title_entries = re.split(cacm_chunk_add_cross, no_title)\n      cacm_txt_data[id]['publication_date'] = no_title_entries[0].strip() # save publication date\n      cacm_txt_data[id]['add_date'] = no_title_entries[1].strip() # save add date\n      cacm_txt_data[id]['cross-references'] = no_title_entries[2].strip() # save cross-references\n")),(0,r.kt)("p",null,"The CISI also had the problem that not all the information was always given. Every entry should contain an ID (.I), title (.T), text (.W), publication date (.B), author (.A), and cross-references (.X). But some entries had more than one author tag. These entries overlapped with the entries for which the information about the publication date was missing:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'.I 33\n.T\nThe "Half-Life" of Some Scientific and Technical Literatures\n.A\nBurton, R.E.\n.A\nKebler, R.W.\n.W\n   A consideration of the analogy between the half-life of radioactive\nsubstances and the rate of obsolescence of scientific literature.. The validity\nof this analogy suggest the possibility of more accurate prognostications\nconcerning the period of time during which scientific literature may by used\nand hence might help to guide the planning of library collections and\ntechnical information services..\n.X\n33        19        33\n36        2          33\n41        1          33\n')),(0,r.kt)("p",null,"Therefore, we only needed one nested if clause:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"cisi_title_start = re.compile('[\\n]\\.T')\ncisi_author_start = re.compile('[\\n]\\.A')\ncisi_date_start = re.compile('[\\n]\\.B')\ncisi_text_start = re.compile('[\\n]\\.W')\ncisi_cross_start = re.compile('[\\n]\\.X')\n \n# process the document data\n \ncisi_txt_data = defaultdict(dict)\n \nfor line in cisi_txt_list:\n  entries = re.split(cisi_title_start,line,1)\n  id = entries[0].strip()#save the id\n  no_id = entries[1]\n \n  if len(re.split(cisi_author_start, no_id)) >= 2: # is there just one author?\n    no_id_entries = re.split(cisi_author_start, no_id,1)\n    cisi_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n    no_title = no_id_entries[1]\n \n    if len(re.split(cisi_date_start, no_title)) > 1: # is there a publication date?\n      no_title_entries = re.split(cisi_date_start, no_title)\n      cisi_txt_data[id]['author'] = no_title_entries[0].strip() # save author\n      no_author = no_title_entries[1]\n      no_author_entries = re.split(cisi_text_start, no_author)\n      cisi_txt_data[id]['publication_date'] = no_author_entries[0].strip() # save publication date\n      no_author_date = no_author_entries[1]\n    else:\n      no_title_entries = re.split(cisi_text_start, no_title)\n      cisi_txt_data[id]['author'] = no_title_entries[0].strip() # save author\n      no_author_date = no_title_entries[1]\n \n  else:\n    no_id_entries = re.split(cisi_author_start, no_id)\n    cisi_txt_data[id]['title'] = no_id_entries[0].strip() # save title\n    cisi_txt_data[id]['author'] = no_id_entries[1].strip() # save the first author\n    no_title_entries = re.split(cisi_text_start, no_title)\n    cisi_txt_data[id]['author'] += ','+no_title_entries[0].strip() # save the second author\n    no_author_date = no_title_entries[1]\n \n  last_entries = re.split(cisi_cross_start, no_author_date)\n  cisi_txt_data[id]['text'] = last_entries[0].strip() # save text\n  cisi_txt_data[id]['cross-refrences'] = last_entries[1].strip() # save cross references\n")),(0,r.kt)("p",null,"These examples show you how important it is to know your data when parsing and to be prepared for any irregularities, especially when it comes to manually annotated data."),(0,r.kt)("h4",{id:"43-unexpected-text-separators"},"4.3. Unexpected Text Separators"),(0,r.kt)("p",null,"In addition to the missing information, irregularities in the distance between the entry markers can also lead to a lot of frustration while parsing. The document and the query files of LISA and NPL were a bit inconsistent with the number of spaces around the entry markers."),(0,r.kt)("p",null,"For the LISA corpus, irregular spaces became a problem both in the document files and in the query files. By \u201cirregular spaces\u201d we mean, for example more than one space, or a combination of spaces, tabs, and others.\nAs with most corpora, you could split the entries using a marker and then save the information in a dictionary.\nWith LISA however, the entries looked like this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Document  501\nLIBRARY AND INFORMATION SERVICES FOR THE PUBLIC: PROCEEDINGS OF THE 8TH\nCONFERENCE OF THE PAPUA NEW GUINEA LIBRARY ASSOCIATION.\n \nTHE CONFERENCE WAS HELD AT THE ADMINISTRATIVE COLLEGE OF PAPUA NEW GUINEA,\nWAIGANI, PORT MORESBY, 18-19 OCT 79. PAPERS ARE IN 5 SECTIONS: STRATEGIES IN\nTHE PLANNING OF LIBRARY AND INFORMATION SERVICES; STATE OF LIBRARIES FOR THE\nPUBLIC IN PAPUA NEW GUINEA; LITERACY AND THE LIBRARY; REACHING OUT: ACCESS TO\nLIBRARY-BASED INFORMATION SERVICES IN THE RURAL AREAS OF PAPUA NEW GUINEA; AND\nAGENCIES INVOLVED IN INFORMATION WORK. TRANSCRIPTIONS OF QUESTION AND ANSWER\nSESSIONS ARE ALSO INCLUDED.\n********************************************\n")),(0,r.kt)("p",null,"The entries were separated by splitting at the ",(0,r.kt)("inlineCode",{parentName:"p"},"txt_entry_marker")," and all empty lines were removed from the resulting list.\nEvery document contains information about its ID, title and text. To get the ID we removed the string ",(0,r.kt)("inlineCode",{parentName:"p"},"Document")," beforehand.\nFor the title, the 1-2 newlines with the regex ",(0,r.kt)("inlineCode",{parentName:"p"},"doc_strip")," were replaced by an empty string, as this made the empty line between the title and text an empty entry.\nUsing the indexes of these empty entries, we could then save the title and text separately:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"txt_entry_marker = re.compile('\\*{44}',re.MULTILINE)\n \ndoc_strip = re.compile('\\n?Document {1,2}')\n \nlisa_txt_list_stripped = []\nlisa_txt_data = defaultdict(dict)\n \nfor el in lisa_txt_list:\n  lisa_txt_list_stripped.append(re.sub(doc_strip,'', el))\n \nfor entry in lisa_txt_list_stripped:\n  parts = entry.split('\\n')\n  empty_index = parts.index('')\n  ID = parts[0]\n  title = parts[1:empty_index]\n  text = parts[empty_index+1:]\n  lisa_txt_data[ID]['title'] = title\n  lisa_txt_data[ID]['text'] = text\n")),(0,r.kt)("p",null,"The query files were a little easier to handle when splitting at the newlines, it was only necessary to handle the first line separately because it does not start with a newline:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# process the query data\nlisa_qry_data = defaultdict(dict)\n \n# the first line is a special case because it doesn't start with a newline\nfirst_line = lisa_qry_list[0]\nfirst_question = ' '.join(first_line[1:])\nlisa_qry_data[int(first_line[0])]['question'] = first_question\n \n# after that every line can be handled in the same way\nfor n in range(0,len(lisa_qry_list)-1):\n  line = re.split('\\n',lisa_qry_list[n+1])\n  question = ' '.join(line[2:])\n  lisa_qry_data[int(line[1])]['question'] = question\n")),(0,r.kt)("p",null,"In contrast to LISA, the NPL corpus only contains ID and text. That simplified the handling of irregular spaces:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"1\ncompact memories have flexible capacities  a digital data storage\nsystem with capacity up to bits and random and or sequential access\nis described\n   /\n")),(0,r.kt)("p",null,"The document, query and relevance assessments files had different newlines around the entry marker which caused some difficulties. With this way of splitting we didn't lose any data:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"txt_entry_marker = re.compile('\\n   /\\n')\nqry_entry_marker = re.compile('\\n/\\n')\nrel_entry_marker = re.compile('\\n   /\\n')\n \n# process the documents\n \nnpl_txt_data = defaultdict(dict)\n \nfor entry in npl_txt_list:\n  splitted = entry.split('\\n')\n  splitted = list(filter(None, splitted))\n  ID = splitted[0]\n  text = ' '.join(map(str, splitted[1:]))\n  npl_txt_data[ID]['text'] = text\n")),(0,r.kt)("h4",{id:"43-number-separators"},"4.3. Number Separators"),(0,r.kt)("p",null,"Some relevance assessment files were difficult to parse, especially in the Time and LISA corpora."),(0,r.kt)("p",null,"In the LISA corpus, we had to be a little more creative, as some relevance document references were also stored on the following line."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"           1           2        3392        3396                                \n           2           2        2623        4291                                \n           3           5        1407        1431        3794        3795        \n        3796         \n")),(0,r.kt)("p",null,"We split the whole file into a list and deleted all empty entries. Since the number of relevant documents is in the second column, we can use this to mathematically calculate at which index the next ID comes and which document IDs are relevant for the actual ID:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# process relevance assessments without rating\nlisa_rel = defaultdict(list)\n \nwith open (PATH_TO_LISA_REL,'r') as f:\n  file = f.read().strip('       ').replace('\\n','')\n  lines = re.split(' ',file)\n  lines = list(filter(None, lines))\n  n = 0\n  while n < len(lines):\n    ID = int(lines[n])\n    num_rel = int(lines[n+1])\n    rels = lines[(n+2):(n+num_rel+2)]\n    lisa_rel[ID].extend(rels)\n    n = n+1+num_rel+1\n")),(0,r.kt)("p",null,"The Time corpus has all relevant document references in the same line as the ID, but there are also irregularities here."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"8  339 358\n \n9   61 155 156 242 269 315 339 358\n \n10  61 156 242 269 339 358\n \n11 195 198\n \n12  61 155 156 242 269 339 358\n \n13  87 170 185\n \n14 269\n")),(0,r.kt)("p",null,"The number of spaces between the ID and the first document ID vary a lot, so we have to replace the spaces several times with empty strings, split everything into a list and then remove all empty entries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# process relevance assessments without rating\ntime_rel = defaultdict(list)\n \nrel_marker = re.compile('            \\n        ')\nrel_split = re.compile('\\n')\n \nwith open (PATH_TO_TIME_REL,'r') as f:\n  for lines in f:\n    line = lines.strip().replace('   ',' ').replace('  ',' ').split(' ')\n    if len(line) > 1:\n      time_rel[int(line[0])].extend(line[1:])\n")),(0,r.kt)("h3",{id:"5-conclusion"},"5. Conclusion"),(0,r.kt)("p",null,"Regardless of which text you are parsing and for which project, it is always important to look at your data and analyze it well. Our guide shows you examples of how you can access such data.\nYou can find our already parsed data ",(0,r.kt)("a",{parentName:"p",href:"/docs/guides/data-comparison"},"here"),"."),(0,r.kt)("br",null),(0,r.kt)("br",null),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Acknowledgements:"),(0,r.kt)("br",null),"\nThanks to Irina Temnikova for proofreading this article."),(0,r.kt)("div",{className:"col text--right"},(0,r.kt)("em",null,(0,r.kt)("small",null,"Written by ",(0,r.kt)("strong",null,"Miriam Rupprecht"),",  August 2020"))))}c.isMDXComponent=!0}}]);