(self.webpackChunkpragmalingu_github_io=self.webpackChunkpragmalingu_github_io||[]).push([[16],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return u},kt:function(){return d}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},l=Object.keys(e);for(r=0;r<l.length;r++)n=l[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)n=l[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var o=r.createContext({}),m=function(e){var t=r.useContext(o),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=m(e.components);return r.createElement(o.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,l=e.originalType,o=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=m(n),d=a,h=c["".concat(o,".").concat(d)]||c[d]||p[d]||l;return n?r.createElement(h,i(i({ref:t},u),{},{components:n})):r.createElement(h,i({ref:t},u))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var l=n.length,i=new Array(l);i[0]=c;var s={};for(var o in t)hasOwnProperty.call(t,o)&&(s[o]=t[o]);s.originalType=e,s.mdxType="string"==typeof e?e:a,i[1]=s;for(var m=2;m<l;m++)i[m]=n[m];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}c.displayName="MDXCreateElement"},3919:function(e,t,n){"use strict";function r(e){return!0===/^(\w*:|\/\/)/.test(e)}function a(e){return void 0!==e&&!r(e)}n.d(t,{b:function(){return r},Z:function(){return a}})},4996:function(e,t,n){"use strict";n.d(t,{C:function(){return l},Z:function(){return i}});var r=n(2263),a=n(3919);function l(){var e=(0,r.Z)().siteConfig,t=(e=void 0===e?{}:e).baseUrl,n=void 0===t?"/":t,l=e.url;return{withBaseUrl:function(e,t){return function(e,t,n,r){var l=void 0===r?{}:r,i=l.forcePrependBaseUrl,s=void 0!==i&&i,o=l.absolute,m=void 0!==o&&o;if(!n)return n;if(n.startsWith("#"))return n;if((0,a.b)(n))return n;if(s)return t+n;var u=n.startsWith(t)?n:t+n.replace(/^\//,"");return m?e+u:u}(l,n,e,t)}}}function i(e,t){return void 0===t&&(t={}),(0,l().withBaseUrl)(e,t)}},711:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return o},metadata:function(){return m},toc:function(){return u},default:function(){return c}});var r=n(2122),a=n(9756),l=(n(7294),n(3905)),i=n(4996),s={id:"experiment1",title:"Stemming Experiment",showAuthor:!0,author:"Samy Ateia and Miriam Rupprecht",date:"September 2020",sidebar_label:"Stemming",custom_edit_url:null,description:"Experiment with two different stemming approaches in Elasticsearch",keywords:["stemming","hunspell stemmer","algorithmic stemming","Elasticsearch"]},o=void 0,m={unversionedId:"experiments/experiment1",id:"experiments/experiment1",isDocsHomePage:!1,title:"Stemming Experiment",description:"Experiment with two different stemming approaches in Elasticsearch",source:"@site/docs/experiments/experiment1.mdx",sourceDirName:"experiments",slug:"/experiments/experiment1",permalink:"/docs/experiments/experiment1",editUrl:null,version:"current",frontMatter:{id:"experiment1",title:"Stemming Experiment",showAuthor:!0,author:"Samy Ateia and Miriam Rupprecht",date:"September 2020",sidebar_label:"Stemming",custom_edit_url:null,description:"Experiment with two different stemming approaches in Elasticsearch",keywords:["stemming","hunspell stemmer","algorithmic stemming","Elasticsearch"]},sidebar:"experiments",previous:{title:"Introduction",permalink:"/docs/experiments/experiments-intro"},next:{title:"Sentence Embeddings",permalink:"/docs/experiments/experiment2"}},u=[{value:"1. Standard Elasticsearch Analyzer",id:"1-standard-elasticsearch-analyzer",children:[]},{value:"2. Stemming",id:"2-stemming",children:[]},{value:"3. Results",id:"3-results",children:[]}],p={toc:u};function c(e){var t=e.components,n=(0,a.Z)(e,["components"]);return(0,l.kt)("wrapper",(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"For our first experiment, we created a Google Colab Notebook that runs an Elasticsearch instance and compared the ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-analyser.html"},"standard Elasticsearch analyzer")," with two built-in stemming methods.\nTo do this, we parsed and indexed ",(0,l.kt)("a",{parentName:"p",href:"http://ir.dcs.gla.ac.uk/resources/test_collections/"},"these 8 publically available datasets"),", provided by the University of Glasgow, with the different analyzers\nand evaluated them with the Elasticsearch ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html"},"Ranking Evaluation API"),".",(0,l.kt)("br",{parentName:"p"}),"\n",(0,l.kt)("a",{parentName:"p",href:"https://pragmalingu.de/docs/guides/how-to-parse"},"Our Parsing Guide")," shows you how these datasets are structured and how we preprocessed them for indexing.\nThe complete code - and workflow to arrive at the results presented here - is available in our ",(0,l.kt)("a",{parentName:"p",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb"},"Experiment Notebook")," where you can reproduce this experiment step by step."),(0,l.kt)("p",null,"These are the two built-in methods that we compared to the ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-analyser.html"},"standard Elasticsearch analyzer"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-stemmer-tokenfilter.html"},"Standard English Stemmer")," "),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-hunspell-tokenfilter.html"},"Hunspell Token Filter")," ")),(0,l.kt)("h3",{id:"1-standard-elasticsearch-analyzer"},"1. Standard Elasticsearch Analyzer"),(0,l.kt)("p",null,"We ran our searches with the ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-multi-match-query.html"},"multi-match query")," and used the default standard analyzer.\nIt searches multiple fields of the documents - in our case 'text' and 'title' - and by default uses the highest matching score from one field to rank the document."),(0,l.kt)("p",null,"We evaluated the ranking on the 20 highest ranked documents returned by each query."),(0,l.kt)("p",null,"The following is an example request against the Ranking Evaluation API to evaluate a query on the ADI Corpus:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'#GET adi-corpus/_rank_eval\n{\n    "metric": {\n        "recall": {\n            "k": 20,\n            "relevant_rating_threshold": 1\n        }\n    },\n   "requests": [{\n            "id": "Query_1",\n            "request": {\n                "query": {\n                    "multi_match": {\n                        "query": "How can actually pertinent data, as opposed to references or entire articles  themselves, be retrieved automatically in response to information requests?",\n                        "fields": ["title", "text"]\n                    }\n                }\n            },\n            "ratings": [{\n                    "_index": "adi-corpus",\n                    "_id": "17",\n                    "rating": 1\n                }, {\n                    "_index": "adi-corpus",\n                    "_id": "46",\n                    "rating": 1\n                }, {\n                    "_index": "adi-corpus",\n                    "_id": "62",\n                    "rating": 1\n                }\n            ]\n        }\n   ]\n}\n')),(0,l.kt)("p",null,"For our experiment we evaluated the ",(0,l.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Precision_and_recall"},"Precision and Recall")," at K. These are metrics provided by the Ranking Evaluation API of Elasticsearch.\nThe Elasticsearch documentation of the Ranking Evaluation API gives an ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-rank-eval.html#_available_evaluation_metrics"},"overview of all available metrics"),".\nWe chose precision and recall and calculated the F1-score , which is often used for ",(0,l.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/F-score#Applications"},"measuring search performance")," , with them."),(0,l.kt)("p",null,"These were the results without any further processing of the data, using the multi-match query of Elasticsearch:"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Standard Analyzer"),(0,l.kt)("th",{parentName:"tr",align:null},"ADI"),(0,l.kt)("th",{parentName:"tr",align:null},"CACM"),(0,l.kt)("th",{parentName:"tr",align:null},"CISI"),(0,l.kt)("th",{parentName:"tr",align:null},"Cranfield"),(0,l.kt)("th",{parentName:"tr",align:null},"LISA"),(0,l.kt)("th",{parentName:"tr",align:null},"Medline"),(0,l.kt)("th",{parentName:"tr",align:null},"NPL"),(0,l.kt)("th",{parentName:"tr",align:null},"Time"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Recall"),(0,l.kt)("td",{parentName:"tr",align:null},"0.537"),(0,l.kt)("td",{parentName:"tr",align:null},"0.283"),(0,l.kt)("td",{parentName:"tr",align:null},"0.103"),(0,l.kt)("td",{parentName:"tr",align:null},"0.51"),(0,l.kt)("td",{parentName:"tr",align:null},"0.368"),(0,l.kt)("td",{parentName:"tr",align:null},"0.335"),(0,l.kt)("td",{parentName:"tr",align:null},"0.24"),(0,l.kt)("td",{parentName:"tr",align:null},"0.772")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Precision"),(0,l.kt)("td",{parentName:"tr",align:null},"0.12"),(0,l.kt)("td",{parentName:"tr",align:null},"0.14"),(0,l.kt)("td",{parentName:"tr",align:null},"0.154"),(0,l.kt)("td",{parentName:"tr",align:null},"0.182"),(0,l.kt)("td",{parentName:"tr",align:null},"0.163"),(0,l.kt)("td",{parentName:"tr",align:null},"0.378"),(0,l.kt)("td",{parentName:"tr",align:null},"0.218"),(0,l.kt)("td",{parentName:"tr",align:null},"0.15")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"F1-Score"),(0,l.kt)("td",{parentName:"tr",align:null},"0.196"),(0,l.kt)("td",{parentName:"tr",align:null},"0.187"),(0,l.kt)("td",{parentName:"tr",align:null},"0.123"),(0,l.kt)("td",{parentName:"tr",align:null},"0.268"),(0,l.kt)("td",{parentName:"tr",align:null},"0.226"),(0,l.kt)("td",{parentName:"tr",align:null},"0.355"),(0,l.kt)("td",{parentName:"tr",align:null},"0.229"),(0,l.kt)("td",{parentName:"tr",align:null},"0.251")))),(0,l.kt)("h3",{id:"2-stemming"},"2. Stemming"),(0,l.kt)("p",null,"To experiment with stemming, Elasticsearch provides several built-in stemming methods. We evaluated two of them.\nFirst is the algorithmic stemmer; it applies a series of rules to each word to reduce them to their stems.\nIn Elasticsearch this is called the ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-stemmer-tokenfilter.html"},"Stemmer Token Filter"),".\nIn addition, there is the dictionary stemmer which replaces unstemmed words with stemmed variants from a provided dictionary.\nThe Elasticsearch built-in method is called the ",(0,l.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-hunspell-tokenfilter.html"},"Hunspell Token Filter"),". "),(0,l.kt)("details",null,(0,l.kt)("summary",null,'What is "Stemming"?'),(0,l.kt)("p",null,"The goal of stemming is to remove all morphological features from a word and create truncated, ambiguous ",(0,l.kt)("strong",{parentName:"p"},"Stems"),". Therefore, it tries to strip off suffixes at the end of a word.",(0,l.kt)("br",null),"\nFor example, ",(0,l.kt)("inlineCode",{parentName:"p"},"learning")," changes to ",(0,l.kt)("inlineCode",{parentName:"p"},"learn")," after stemming. ",(0,l.kt)("br",null),"\nIf the stemmer cuts off too much information the word could become too short and lose semantic meaning; this is called overstemming.")),(0,l.kt)("h4",{id:"21-stemmer-token-filter"},"2.1. Stemmer Token Filter"),(0,l.kt)("p",null,"The ",(0,l.kt)("em",{parentName:"p"},"Stemmer Token Filter")," supports different languages, but since our corpora were all in English we used the English stemmer.\nCompared to the dictionary approach, algorithmic stemming requires less memory and is significantly faster.\nFor this reason, it is usually better to use the ",(0,l.kt)("em",{parentName:"p"},"Stemmer Token Filter"),". The configuration in Elasticsearch is not complicated and can be done quickly."),(0,l.kt)("p",null,"Irregular words or names can cause strange forms that don't give any helpful information since the filter is only rules-based.\nIn spite of this, we expected an improvement to the standard Elasticsearch operator. This is how we configured the stemming analyser in Elasticsearch:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'stemming_analyser = {\n    "filter": {\n        "eng_stemmer": {\n            "type": "stemmer",\n            "name": "english"\n        }\n    },\n    "analyzer": {\n        "default": {\n            "tokenizer": "standard",\n            "filter": ["lowercase", "eng_stemmer"]\n        }\n    }\n}\n')),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=Q9EMclEPLvMS"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),(0,l.kt)("p",null,"Afterwards, we incorporated the ",(0,l.kt)("inlineCode",{parentName:"p"},"stemming_analyser")," into the index settings, which we then used to index the documents of each corpus:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'settings = {\n    "settings": {\n        "number_of_shards": 1,\n        "number_of_replicas": 0,\n        "analysis": stemming_analyser\n    }\n}\n')),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=Q9EMclEPLvMS"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),(0,l.kt)("p",null,"These were the results with the ",(0,l.kt)("em",{parentName:"p"},"Stemmer Token Filter")," applied:"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Stemmer Token Filter"),(0,l.kt)("th",{parentName:"tr",align:null},"ADI"),(0,l.kt)("th",{parentName:"tr",align:null},"CACM"),(0,l.kt)("th",{parentName:"tr",align:null},"CISI"),(0,l.kt)("th",{parentName:"tr",align:null},"Cranfield"),(0,l.kt)("th",{parentName:"tr",align:null},"LISA"),(0,l.kt)("th",{parentName:"tr",align:null},"Medline"),(0,l.kt)("th",{parentName:"tr",align:null},"NPL"),(0,l.kt)("th",{parentName:"tr",align:null},"Time"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Recall"),(0,l.kt)("td",{parentName:"tr",align:null},"0.608"),(0,l.kt)("td",{parentName:"tr",align:null},"0.321"),(0,l.kt)("td",{parentName:"tr",align:null},"0.121"),(0,l.kt)("td",{parentName:"tr",align:null},"0.538"),(0,l.kt)("td",{parentName:"tr",align:null},"0.413"),(0,l.kt)("td",{parentName:"tr",align:null},"0.343"),(0,l.kt)("td",{parentName:"tr",align:null},"0.292"),(0,l.kt)("td",{parentName:"tr",align:null},"0.78")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Precision"),(0,l.kt)("td",{parentName:"tr",align:null},"0.13"),(0,l.kt)("td",{parentName:"tr",align:null},"0.177"),(0,l.kt)("td",{parentName:"tr",align:null},"0.169"),(0,l.kt)("td",{parentName:"tr",align:null},"0.193"),(0,l.kt)("td",{parentName:"tr",align:null},"0.187"),(0,l.kt)("td",{parentName:"tr",align:null},"0.38"),(0,l.kt)("td",{parentName:"tr",align:null},"0.259"),(0,l.kt)("td",{parentName:"tr",align:null},"0.152")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"F1-Score"),(0,l.kt)("td",{parentName:"tr",align:null},"0.214"),(0,l.kt)("td",{parentName:"tr",align:null},"0.228"),(0,l.kt)("td",{parentName:"tr",align:null},"0.141"),(0,l.kt)("td",{parentName:"tr",align:null},"0.284"),(0,l.kt)("td",{parentName:"tr",align:null},"0.257"),(0,l.kt)("td",{parentName:"tr",align:null},"0.36"),(0,l.kt)("td",{parentName:"tr",align:null},"0.274"),(0,l.kt)("td",{parentName:"tr",align:null},"0.255")))),(0,l.kt)("h4",{id:"22-hunspell-token-filter"},"2.2. Hunspell Token Filter"),(0,l.kt)("p",null,"The ",(0,l.kt)("em",{parentName:"p"},"Hunspell Token Filter")," from Elasticsearch recognizes irregular words and should, therefore, preprocess them better.\nHowever, we must keep in mind that words that do not appear in the dictionary are not processed correctly.\nIn addition, a large dictionary will naturally require significantly more time and resources.\nSince the dictionaries we used were not optimized for the domains of our corpora, we didn't expect a significant change in the results compared to the ",(0,l.kt)("em",{parentName:"p"},"Stemmer Token Filter"),". "),(0,l.kt)("p",null,"The procedure of the ",(0,l.kt)("em",{parentName:"p"},"Hunspell Token Filter")," is similar to a lemmatization, but the words are not always reduced to the lemma with Hunspell.\nSo the meaning of the words is not sufficiently addressed every time."),(0,l.kt)("details",null,(0,l.kt)("summary",null,'What is "Lemmatization"?'),"Lemmatization tries to connect words to their root form - their **Lemma** - by removing all morphological rules. It's similar to stemming, but it takes affixes and plural forms into account as well, instead of simply stripping away suffixes.",(0,l.kt)("br",null),"For example, `mice` would connect to `mouse`, and `froze` & `frozen` to `freeze`."),(0,l.kt)("br",null),(0,l.kt)("br",null),"The procedure is the same as with the *Stemmer Token Filter*. First, we configured the Hunspell Stemming analyser:",(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'#the order of filter and analyser is arbitrary\ndictionary_analyser = {\n    "filter" : {\n        "dictionary_stemmer" : {\n          "type" : "hunspell",\n          "locale" : "en_US",\n          "dedup" : True  #duplicate tokens are removed from the filter\u2019s output\n        }\n    },\n    "analyzer" : {\n        "default" : {\n            "tokenizer" : "standard",\n            "filter" : ["lowercase", "dictionary_stemmer"]\n        }\n    }\n}\n')),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=Y1DRyRSxZZE7"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),"Afterwards, we embedded the analyser into the settings to index our documents with it:",(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'settings = {\n    "settings": {\n        "number_of_shards": 1,\n        "number_of_replicas": 0,\n        "analysis": dictionary_analyser\n    }\n')),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=Y1DRyRSxZZE7"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),"These were the results of the *Hunspell Token Filter*:",(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Hunspell"),(0,l.kt)("th",{parentName:"tr",align:null},"ADI"),(0,l.kt)("th",{parentName:"tr",align:null},"CACM"),(0,l.kt)("th",{parentName:"tr",align:null},"CISI"),(0,l.kt)("th",{parentName:"tr",align:null},"Cranfield"),(0,l.kt)("th",{parentName:"tr",align:null},"LISA"),(0,l.kt)("th",{parentName:"tr",align:null},"Medline"),(0,l.kt)("th",{parentName:"tr",align:null},"NPL"),(0,l.kt)("th",{parentName:"tr",align:null},"Time"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Recall"),(0,l.kt)("td",{parentName:"tr",align:null},"0.575"),(0,l.kt)("td",{parentName:"tr",align:null},"0.312"),(0,l.kt)("td",{parentName:"tr",align:null},"0.12"),(0,l.kt)("td",{parentName:"tr",align:null},"0.528"),(0,l.kt)("td",{parentName:"tr",align:null},"0.405"),(0,l.kt)("td",{parentName:"tr",align:null},"0.335"),(0,l.kt)("td",{parentName:"tr",align:null},"0.3"),(0,l.kt)("td",{parentName:"tr",align:null},"0.777")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"Precision"),(0,l.kt)("td",{parentName:"tr",align:null},"0.127"),(0,l.kt)("td",{parentName:"tr",align:null},"0.164"),(0,l.kt)("td",{parentName:"tr",align:null},"0.167"),(0,l.kt)("td",{parentName:"tr",align:null},"0.19"),(0,l.kt)("td",{parentName:"tr",align:null},"0.184"),(0,l.kt)("td",{parentName:"tr",align:null},"0.368"),(0,l.kt)("td",{parentName:"tr",align:null},"0.259"),(0,l.kt)("td",{parentName:"tr",align:null},"0.151")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"F1-Score"),(0,l.kt)("td",{parentName:"tr",align:null},"0.208"),(0,l.kt)("td",{parentName:"tr",align:null},"0.215"),(0,l.kt)("td",{parentName:"tr",align:null},"0.14"),(0,l.kt)("td",{parentName:"tr",align:null},"0.28"),(0,l.kt)("td",{parentName:"tr",align:null},"0.253"),(0,l.kt)("td",{parentName:"tr",align:null},"0.351"),(0,l.kt)("td",{parentName:"tr",align:null},"0.278"),(0,l.kt)("td",{parentName:"tr",align:null},"0.252")))),(0,l.kt)("h3",{id:"3-results"},"3. Results"),(0,l.kt)("p",null,"To compare our results properly we plotted Recall, Precision, and F1-Score for every method on every corpus."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Recall")),(0,l.kt)("details",null,(0,l.kt)("summary",null,'What is "Recall"?'),"Recall measures the probability that relevant documents are retrieved. Therefore, the number of all retrieved relevant documents is divided by the number of all documents that are labeled as relevant. For example, if we were to return 10 documents, 8 of which are relevant to our search and 4 of these are retrieved, then the Recall measure would be 4/8 = 0.5.",(0,l.kt)("p",null,"To measure Recall it is necessary to have the relevant documents labeled. Recall only looks at relevant documents that were retrieved and does not take into account any irrelevant documents which may have been retrieved.")),(0,l.kt)("img",{alt:"Recall",src:(0,i.Z)("img/EXP1_Recall.svg"),className:"content"}),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=CemuLaUAMHKP"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Precision")),(0,l.kt)("details",null,(0,l.kt)("summary",null,'What is "Precision"?'),"Precision measures the probability that retrieved documents are relevant to the search query. Therefore, the number of all retrieved relevant documents is divided by the number of all retrieved documents. For example if we retrieve 10 search results and only 5 are relevant for our search, the Precision measure would be: 5/10 = 0.5.",(0,l.kt)("p",null,"To measure the Precision it is necessary to have the relevant documents labeled as such. Precision only looks at the documents that are retrieved and does not account for relevant documents which were not retrieved.")),(0,l.kt)("img",{alt:"Recall",src:(0,i.Z)("img/EXP1_Precision.svg"),className:"content"}),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=kJbezFbtMVp3"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"F1-Score")),(0,l.kt)("details",null,(0,l.kt)("summary",null,'What is "F1-Score"?'),"The F1-Score measures a harmonic mean between Precision and Recall. Therefore we multiply Precision and Recall by two and divide it by the sum of Precision and Recall: ",(0,l.kt)("br",null),"`F1-Score=(2*Precision*Recall)/(Precision+Recall)` This is the simplest way to balance both Precision and Recall, there are also other common options to weight them differently."),(0,l.kt)("img",{alt:"Recall",src:(0,i.Z)("img/EXP1_FScore.svg"),className:"content"}),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb#scrollTo=Gm1Aej_-T9e0"},(0,l.kt)("button",{className:"buttons"},"Run it in Google Colab")),(0,l.kt)("br",null),(0,l.kt)("br",null),(0,l.kt)("p",null,"It is apparent that the algorithmic stemmer offers some improvements over no stemming. The dictionary based hunspell stemming seems to perform either better or worse depending on the corpora.\nFor a more detailed analysis check out our ",(0,l.kt)("a",{parentName:"p",href:"/docs/comparisons/stemming"},"Simple Search vs. Stemming Comparison"),"."),(0,l.kt)("a",{className:"buttons",href:"https://colab.research.google.com/github/pragmalingu/experiments/blob/master/01_Stemming/Experiment/First_Experiment_Stemming.ipynb"},(0,l.kt)("button",{className:"buttons"},"Try it yourself!")),(0,l.kt)("br",null),(0,l.kt)("br",null),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Acknowledgements:"),(0,l.kt)("br",null),"\nThanks to Dario Alves for implementing the Stemmers inside of Google Colab for Elasticsearch and Kenny Hall for proofreading this article."),(0,l.kt)("div",{className:"col text--right"},(0,l.kt)("em",null,(0,l.kt)("small",null,"Written by ",(0,l.kt)("strong",null,"Samy Ateia")," and ",(0,l.kt)("strong",null,"Miriam Rupprecht"),",  September 2020"))))}c.isMDXComponent=!0}}]);